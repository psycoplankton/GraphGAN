{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of DeepWalk Algorithm to generate Node Embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"/home/student/Vansh/GraphGAN/CA-GrQc Dataset/CA-GrQc_train.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NodeIDfrom</th>\n",
       "      <th>NodeIDto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4095</td>\n",
       "      <td>546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3213</td>\n",
       "      <td>2059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1882</td>\n",
       "      <td>3269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4897</td>\n",
       "      <td>2661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2621</td>\n",
       "      <td>1718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13041</th>\n",
       "      <td>830</td>\n",
       "      <td>5103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13042</th>\n",
       "      <td>1842</td>\n",
       "      <td>3805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13043</th>\n",
       "      <td>3468</td>\n",
       "      <td>1758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13044</th>\n",
       "      <td>4889</td>\n",
       "      <td>3784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13045</th>\n",
       "      <td>2796</td>\n",
       "      <td>504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13046 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       NodeIDfrom  NodeIDto\n",
       "0            4095       546\n",
       "1            3213      2059\n",
       "2            1882      3269\n",
       "3            4897      2661\n",
       "4            2621      1718\n",
       "...           ...       ...\n",
       "13041         830      5103\n",
       "13042        1842      3805\n",
       "13043        3468      1758\n",
       "13044        4889      3784\n",
       "13045        2796       504\n",
       "\n",
       "[13046 rows x 2 columns]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(dataset,\n",
    "                sep = '\\t',\n",
    "                names = [\"NodeIDfrom\", \"NodeIDto\"],\n",
    "                )\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5241"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5119"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create the graph networkx object from the above dataframe\n",
    "\n",
    "G = nx.from_pandas_edgelist(df = df,\n",
    "                             source = \"NodeIDfrom\",\n",
    "                             target = \"NodeIDto\",\n",
    "                             create_using=nx.Graph())\n",
    "len(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_num(num, workers):\n",
    "    if num % workers == 0:\n",
    "        return [num // workers] * workers\n",
    "    else:\n",
    "        return [num // workers] * workers + [num % workers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import math\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "class RandomWalker:\n",
    "    def __init__(self, G, p=1, q=1, use_rejection_sampling=False):\n",
    "        \"\"\"\n",
    "        :param G:\n",
    "        :param p: Return parameter,controls the likelihood of immediately revisiting a node in the walk.\n",
    "        :param q: In-out parameter,allows the search to differentiate between “inward” and “outward” nodes\n",
    "        :param use_rejection_sampling: Whether to use the rejection sampling strategy in node2vec.\n",
    "        \"\"\"\n",
    "        self.G = G\n",
    "        self.p = p\n",
    "        self.q = q\n",
    "        self.use_rejection_sampling = use_rejection_sampling\n",
    "\n",
    "    def deepwalk_walk(self, walk_length, start_node):\n",
    "\n",
    "        walk = [start_node]\n",
    "\n",
    "        while len(walk) < walk_length:\n",
    "            cur = walk[-1]\n",
    "            cur_nbrs = list(self.G.neighbors(cur))\n",
    "            if len(cur_nbrs) > 0:\n",
    "                walk.append(random.choice(cur_nbrs))\n",
    "            else:\n",
    "                break\n",
    "        return walk\n",
    "    \n",
    "    def simulate_walks(self, num_walks, walk_length, workers=1, verbose=0):\n",
    "\n",
    "        G = self.G\n",
    "\n",
    "        nodes = list(G.nodes())\n",
    "\n",
    "        results = Parallel(n_jobs=workers, verbose=verbose, )(\n",
    "            delayed(self._simulate_walks)(nodes, num, walk_length) for num in\n",
    "            partition_num(num_walks, workers))\n",
    "\n",
    "        walks = list(itertools.chain(*results))\n",
    "\n",
    "        return walks\n",
    "\n",
    "    def _simulate_walks(self, nodes, num_walks, walk_length, ):\n",
    "        walks = []\n",
    "        for _ in range(num_walks):\n",
    "            random.shuffle(nodes)\n",
    "            for v in nodes:\n",
    "                if self.p == 1 and self.q == 1:\n",
    "                    walks.append(self.deepwalk_walk(\n",
    "                        walk_length=walk_length, start_node=v))\n",
    "        return walks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class DeepWalk:\n",
    "    def __init__(self, graph, walk_length, num_walks, workers=1):\n",
    "\n",
    "        self.graph = graph\n",
    "        self.w2v_model = None\n",
    "        self._embeddings = {}\n",
    "\n",
    "        self.walker = RandomWalker(\n",
    "            graph, p=1, q=1, )\n",
    "        self.sentences = self.walker.simulate_walks(\n",
    "            num_walks=num_walks, walk_length=walk_length, workers=workers, verbose=1)\n",
    "\n",
    "    def train(self, embed_size=128, window_size=5, workers=3, iter=5, **kwargs):\n",
    "\n",
    "        kwargs[\"sentences\"] = self.sentences\n",
    "        kwargs[\"min_count\"] = kwargs.get(\"min_count\", 0)\n",
    "        kwargs[\"vector_size\"] = embed_size\n",
    "        kwargs[\"sg\"] = 1  # skip gram\n",
    "        kwargs[\"hs\"] = 1  # deepwalk use Hierarchical Softmax\n",
    "        kwargs[\"workers\"] = workers\n",
    "        kwargs[\"window\"] = window_size\n",
    "        kwargs[\"epochs\"] = iter\n",
    "\n",
    "        print(\"Learning embedding vectors...\")\n",
    "        model = gensim.models.Word2Vec(**kwargs)\n",
    "        print(\"Learning embedding vectors done!\")\n",
    "\n",
    "        self.w2v_model = model\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.6s finished\n"
     ]
    }
   ],
   "source": [
    "deepwalk = DeepWalk(G, walk_length=10, num_walks=10)\n",
    "sentences = deepwalk.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "model = gensim.models.Word2Vec(sentences=sentences,\n",
    "                 vector_size=50,\n",
    "                 epochs=3,\n",
    "                 window = 5,\n",
    "                 compute_loss=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.36336377,  0.21993694, -0.54842895,  0.14171971, -0.76210135,\n",
       "        -0.40528682, -0.07366546,  0.28831422, -0.6714414 ,  0.21538393,\n",
       "        -0.05992492,  0.05475014, -0.43771958,  0.4424864 , -0.11950689,\n",
       "         0.01076721,  0.1552783 , -0.44117147,  0.36395305, -0.20703627,\n",
       "        -0.12031038,  0.0050295 ,  0.37687257, -0.3541179 ,  0.23381917,\n",
       "        -0.1045076 , -0.20237887,  0.03758082, -0.42053217,  0.11995432,\n",
       "         0.35173428, -0.19082142, -0.01299398,  0.40715382,  0.08225609,\n",
       "         0.55181956,  0.13224381,  0.5249842 ,  0.23315273, -0.5763551 ,\n",
       "        -0.1488933 ,  0.25717974,  0.14607301,  0.22010419,  0.9429984 ,\n",
       "         0.22557394,  0.01911211, -1.0640045 , -0.22505623,  0.21754292],\n",
       "       dtype=float32),\n",
       " 4.228395)"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = []\n",
    "for i in G.nodes():\n",
    "    embeddings.append(model.wv[i]) #/np.linalg.norm(model.wv[i]))\n",
    "embeddings = np.array(embeddings)\n",
    "embeddings[0], np.max(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "embedding_filename = r\"/home/student/Vansh/GraphGAN/Pre-Train Embeddings/deepwalk_embeddings.emb\"\n",
    "index = np.array(G.nodes()).reshape(-1, 1)\n",
    "embedding_matrix = np.hstack([index, embeddings])\n",
    "embedding_list = embedding_matrix.tolist()\n",
    "embedding_str = [str(int(emb[0])) + \" \" + \" \".join([str(x) for x in emb[1:]]) + \"\\n\"\n",
    "                  for emb in embedding_list]\n",
    "with open(embedding_filename, \"w+\") as f:\n",
    "    lines = [str(5119) + \"\\t\" + str(50) + \"\\n\"] + embedding_str\n",
    "    f.writelines(lines)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d006cd09a7ebbb48eee4e86342fa19e01d16df56cb7967e71afee02ac2f94235"
  },
  "kernelspec": {
   "display_name": "Python 3.8.18 64-bit ('graphgan')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
